{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import IPython.display as ipd\nimport librosa.display\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n#from DataLoaderUrbanSounds import DataLoaderUrbanSounds","metadata":{"execution":{"iopub.status.busy":"2022-06-02T19:11:10.084918Z","iopub.execute_input":"2022-06-02T19:11:10.085713Z","iopub.status.idle":"2022-06-02T19:11:10.092202Z","shell.execute_reply.started":"2022-06-02T19:11:10.085648Z","shell.execute_reply":"2022-06-02T19:11:10.091429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2022-06-02T19:11:34.567346Z","iopub.execute_input":"2022-06-02T19:11:34.568212Z","iopub.status.idle":"2022-06-02T19:11:37.085119Z","shell.execute_reply.started":"2022-06-02T19:11:34.568171Z","shell.execute_reply":"2022-06-02T19:11:37.083996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport librosa\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.utils import to_categorical\nimport tensorflow as tf\nfrom tqdm import tqdm\n\n\nclass DataLoaderUrbanSounds():\n    def __init__(self, input_dim):\n        self.AUDIO_DIR = \"../input/urbansound8k\"\n        self.METADATA = pd.read_csv('../input/urbansound8k/UrbanSound8K.csv')\n        self.EXTRACTED_FEATURES = []\n        self.INPUT_DIM = input_dim\n        self.labelencoder = LabelEncoder()\n\n    def __len__(self):\n        return len(self.METADATA)\n\n    def extract_features(self):\n        for index_num, row in tqdm(self.METADATA.iterrows()):\n            file_name = os.path.join(os.path.abspath(self.AUDIO_DIR), 'fold' + str(row[\"fold\"]) + '/',\n                                     str(row[\"slice_file_name\"]))\n            final_class_labels = row[\"class\"]\n            data = self.get_one_file_features_extractor(file_name)\n            self.EXTRACTED_FEATURES.append([data, final_class_labels])\n\n    def get_one_file_features_extractor(self, file_name):\n        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n        mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=self.INPUT_DIM)\n        mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n        return mfccs_scaled_features\n\n    def get_train_test_data(self):\n        ### converting extracted_features to Pandas dataframe\n        extracted_features_df = pd.DataFrame(self.EXTRACTED_FEATURES, columns=['feature', 'class'])\n\n        ### Split the dataset into independent and dependent dataset\n        X = np.array(extracted_features_df['feature'].tolist())\n        y = np.array(extracted_features_df['class'].tolist())\n\n        return X, y\n\n    def get_target_as_one_hot_encoder(self):\n        ### converting extracted_features to Pandas dataframe\n        extracted_features_df = pd.DataFrame(self.EXTRACTED_FEATURES, columns=['feature', 'class'])\n\n        y = np.array(extracted_features_df['class'].tolist())\n        y = to_categorical(self.labelencoder.fit_transform(y))\n        return y\n\n    def get_target_as_label_encoder(self):\n        ### converting extracted_features to Pandas dataframe\n        extracted_features_df = pd.DataFrame(self.EXTRACTED_FEATURES, columns=['feature', 'class'])\n\n        y = np.array(extracted_features_df['class'].tolist())\n        y = self.labelencoder.fit_transform(y)\n        return y\n\n    def split_to_train_test_data(self, X, y, test_size=0.2):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=50)\n        return X_train, X_test, y_train, y_test\n\n    def decode_label(self, predicted_label):\n        return self.labelencoder.inverse_transform(predicted_label)\n\nif __name__ == \"__main__\":\n    print('Dataloader')","metadata":{"execution":{"iopub.status.busy":"2022-06-02T19:11:50.160177Z","iopub.execute_input":"2022-06-02T19:11:50.160544Z","iopub.status.idle":"2022-06-02T19:11:50.531852Z","shell.execute_reply.started":"2022-06-02T19:11:50.160513Z","shell.execute_reply":"2022-06-02T19:11:50.531002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sample audio","metadata":{}},{"cell_type":"code","source":"librosa_audio_data, librosa_sample_rate = librosa.load('../input/urbansound8k/fold4/102102-3-0-0.wav')","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T19:11:55.906435Z","iopub.execute_input":"2022-06-02T19:11:55.906834Z","iopub.status.idle":"2022-06-02T19:11:56.797917Z","shell.execute_reply.started":"2022-06-02T19:11:55.9068Z","shell.execute_reply":"2022-06-02T19:11:56.797099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(librosa_audio_data.shape)\n# Original audio with 1 channel\nplt.figure(figsize=(12, 4))\nplt.plot(librosa_audio_data)\nipd.Audio('../input/urbansound8k/fold4/102102-3-0-0.wav')","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T19:11:58.964828Z","iopub.execute_input":"2022-06-02T19:11:58.965576Z","iopub.status.idle":"2022-06-02T19:11:59.22896Z","shell.execute_reply.started":"2022-06-02T19:11:58.96554Z","shell.execute_reply":"2022-06-02T19:11:59.228212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exploring Metadata","metadata":{}},{"cell_type":"code","source":"metadata = pd.read_csv('../input/urbansound8k/UrbanSound8K.csv')\nmetadata.head()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T19:12:03.405274Z","iopub.execute_input":"2022-06-02T19:12:03.405904Z","iopub.status.idle":"2022-06-02T19:12:03.453533Z","shell.execute_reply.started":"2022-06-02T19:12:03.405869Z","shell.execute_reply":"2022-06-02T19:12:03.452632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training method","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nfrom keras.callbacks import ModelCheckpoint\n\n\ndef train(model, num_epochs, num_batch_size, X_train, y_train, X_test, y_test):\n    ## Trianing my model\n    checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5',\n                                   verbose=1, save_best_only=True)\n    start = datetime.now()\n\n    model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test),\n              callbacks=[checkpointer], verbose=1)\n\n    duration = datetime.now() - start\n    print(\"Training completed in time: \", duration)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T17:36:16.36662Z","iopub.execute_input":"2022-06-02T17:36:16.36753Z","iopub.status.idle":"2022-06-02T17:36:16.379271Z","shell.execute_reply.started":"2022-06-02T17:36:16.36748Z","shell.execute_reply":"2022-06-02T17:36:16.378145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**instantiate DataLoaderUrbanSound class**","metadata":{}},{"cell_type":"code","source":"dl = DataLoaderUrbanSounds(100)  # you can choose your own dim","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T19:12:12.02984Z","iopub.execute_input":"2022-06-02T19:12:12.030197Z","iopub.status.idle":"2022-06-02T19:12:12.050085Z","shell.execute_reply.started":"2022-06-02T19:12:12.030162Z","shell.execute_reply":"2022-06-02T19:12:12.049336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**extract features from all aduio files**\n","metadata":{}},{"cell_type":"code","source":"dl.extract_features()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T19:12:15.698297Z","iopub.execute_input":"2022-06-02T19:12:15.698642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Get Training Data**","metadata":{}},{"cell_type":"code","source":"# get X (train) data\nX, _ = dl.get_train_test_data()\n\n# get y (target) based on the encoder to use\ny = dl.get_target_as_one_hot_encoder()\n#y = dl.get_target_as_label_encoder()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T17:56:39.826954Z","iopub.execute_input":"2022-06-02T17:56:39.827424Z","iopub.status.idle":"2022-06-02T17:56:39.854405Z","shell.execute_reply.started":"2022-06-02T17:56:39.827386Z","shell.execute_reply":"2022-06-02T17:56:39.853496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:56:42.649647Z","iopub.execute_input":"2022-06-02T17:56:42.650292Z","iopub.status.idle":"2022-06-02T17:56:42.656625Z","shell.execute_reply.started":"2022-06-02T17:56:42.650251Z","shell.execute_reply":"2022-06-02T17:56:42.655397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123, stratify=y)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=123)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:56:47.698132Z","iopub.execute_input":"2022-06-02T17:56:47.698542Z","iopub.status.idle":"2022-06-02T17:56:47.897382Z","shell.execute_reply.started":"2022-06-02T17:56:47.698508Z","shell.execute_reply":"2022-06-02T17:56:47.896466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**split data into train and test**","metadata":{}},{"cell_type":"code","source":"X_train = X_train.reshape(-1, 100, 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:57:01.557247Z","iopub.execute_input":"2022-06-02T17:57:01.558159Z","iopub.status.idle":"2022-06-02T17:57:01.562443Z","shell.execute_reply.started":"2022-06-02T17:57:01.558116Z","shell.execute_reply":"2022-06-02T17:57:01.561783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_val = X_val.reshape(-1, 100, 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:57:03.230638Z","iopub.execute_input":"2022-06-02T17:57:03.231479Z","iopub.status.idle":"2022-06-02T17:57:03.236128Z","shell.execute_reply.started":"2022-06-02T17:57:03.231425Z","shell.execute_reply":"2022-06-02T17:57:03.235197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = X_test.reshape(-1, 100, 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:57:05.366497Z","iopub.execute_input":"2022-06-02T17:57:05.367406Z","iopub.status.idle":"2022-06-02T17:57:05.372619Z","shell.execute_reply.started":"2022-06-02T17:57:05.367362Z","shell.execute_reply":"2022-06-02T17:57:05.371625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:57:07.279298Z","iopub.execute_input":"2022-06-02T17:57:07.280148Z","iopub.status.idle":"2022-06-02T17:57:07.287049Z","shell.execute_reply.started":"2022-06-02T17:57:07.280103Z","shell.execute_reply":"2022-06-02T17:57:07.286309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build model and feed in the data","metadata":{}},{"cell_type":"markdown","source":"### Creating RNN","metadata":{}},{"cell_type":"code","source":"import tensorflow\nimport keras\nfrom tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.optimizers import Adam","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-02T17:57:16.688515Z","iopub.execute_input":"2022-06-02T17:57:16.689367Z","iopub.status.idle":"2022-06-02T17:57:16.696642Z","shell.execute_reply.started":"2022-06-02T17:57:16.689313Z","shell.execute_reply":"2022-06-02T17:57:16.695826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape=(100,1)\nmodel = keras.Sequential()\nmodel.add(LSTM(1000,input_shape=input_shape, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(512,input_shape=input_shape, return_sequences=False))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10, activation='softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-02T18:14:47.304465Z","iopub.execute_input":"2022-06-02T18:14:47.305013Z","iopub.status.idle":"2022-06-02T18:14:47.913443Z","shell.execute_reply.started":"2022-06-02T18:14:47.304974Z","shell.execute_reply":"2022-06-02T18:14:47.912385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2022-06-02T18:14:52.828464Z","iopub.execute_input":"2022-06-02T18:14:52.828848Z","iopub.status.idle":"2022-06-02T18:14:52.83969Z","shell.execute_reply.started":"2022-06-02T18:14:52.828816Z","shell.execute_reply":"2022-06-02T18:14:52.838625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=20, batch_size=36, \n                    validation_data=(X_val, y_val), shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-02T18:14:55.418617Z","iopub.execute_input":"2022-06-02T18:14:55.419056Z","iopub.status.idle":"2022-06-02T18:39:37.796708Z","shell.execute_reply.started":"2022-06-02T18:14:55.419022Z","shell.execute_reply":"2022-06-02T18:39:37.795644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adapted from Deep Learning with Python by Francois Chollet, 2018\nhistory_dict=history.history\nloss_values=history_dict['loss']\nacc_values=history_dict['acc']\nval_loss_values = history_dict['val_loss']\nval_acc_values=history_dict['val_acc']\nepochs=range(1,31)\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\nax1.plot(epochs,loss_values,'co',label='Training Loss')\nax1.plot(epochs,val_loss_values,'m', label='Validation Loss')\nax1.set_title('Training and validation loss')\nax1.set_xlabel('Epochs')\nax1.set_ylabel('Loss')\nax1.legend()\nax2.plot(epochs,acc_values,'co', label='Training accuracy')\nax2.plot(epochs,val_acc_values,'m',label='Validation accuracy')\nax2.set_title('Training and validation accuracy')\nax2.set_xlabel('Epochs')\nax2.set_ylabel('Accuracy')\nax2.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TrainLoss, Trainacc = model.evaluate(X_train,y_train)\nTestLoss, Testacc = model.evaluate(X_test, y_test)\ny_pred=model.predict(X_test)\nprint('Confusion_matrix: ',tf.math.confusion_matrix(y_test, np.argmax(y_pred,axis=1)))","metadata":{"execution":{"iopub.status.busy":"2022-06-02T17:38:54.306985Z","iopub.status.idle":"2022-06-02T17:38:54.307527Z","shell.execute_reply.started":"2022-06-02T17:38:54.30733Z","shell.execute_reply":"2022-06-02T17:38:54.307355Z"},"trusted":true},"execution_count":null,"outputs":[]}]}